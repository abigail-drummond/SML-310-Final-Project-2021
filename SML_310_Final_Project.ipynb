{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SML 310 Final Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwNdUaRcoLpB"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn\n",
        "!pip install ppscore"
      ],
      "metadata": {
        "id": "MNs1vfq3SX0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-trJ4Fd4qGsI"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder, LabelBinarizer\n",
        "from sklearn.metrics import confusion_matrix, fbeta_score, accuracy_score, roc_curve, roc_auc_score, recall_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler \n",
        "from imblearn.pipeline import Pipeline, make_pipeline\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Processing"
      ],
      "metadata": {
        "id": "X-NGRfe3btv9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrIvqpMgpwv3"
      },
      "source": [
        "## load the Spillover dataset\n",
        "spillover_path = \"drive/MyDrive/Senior Thesis Data/Spillover_dataset_Sept_22_2020.csv\"\n",
        "spillover_data = pd.read_csv(spillover_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## preprocess the Spillover dataset\n",
        "\n",
        "# select the covariates of interest\n",
        "spillover_data = spillover_data[[\"HostOrder\", \"HostFamily\", \"HostGenus\", \"VirusGenus\", \"VirusFamily\", \"Genome_General\", \"Segmented\", \"Envelope\", \"SeverityDiseaseHumans\", \"ChronicityHumans\", \"Total_transmission\", \"HumanToHumanTransVirus\"]]\n",
        "\n",
        "# remove duplicate rows\n",
        "spillover_data = spillover_data.drop_duplicates()\n",
        "\n",
        "# remove rows with missing data\n",
        "spillover_data = spillover_data[spillover_data.VirusGenus != \"Unassigned\"]\n",
        "spillover_data = spillover_data[spillover_data.SeverityDiseaseHumans != \"SickUnknownCause\"]\n",
        "spillover_data = spillover_data[spillover_data.ChronicityHumans != \"Unknown\"]"
      ],
      "metadata": {
        "id": "w1AUA1Jd9Iu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## because the dataset is unbalanced (some categorical levels only appear once), to avoid the curse of dimensionality after one-hot encoding collapse categorical feature levels that appear >5 times in the dataset\n",
        "spillover_data.loc[spillover_data['HostGenus'].value_counts()[spillover_data['HostGenus']].values < 5, 'HostGenus'] = \"Other\" # (reference: https://stackoverflow.com/questions/22208562/replace-rarely-occurring-values-in-a-pandas-dataframe)\n",
        "\n",
        "spillover_data.loc[spillover_data['HostOrder'].value_counts()[spillover_data['HostOrder']].values < 5, 'HostOrder'] = \"Other\"\n",
        "\n",
        "spillover_data.loc[spillover_data['HostFamily'].value_counts()[spillover_data['HostFamily']].values < 5, 'HostFamily'] = \"Other\"\n",
        "\n",
        "spillover_data.loc[spillover_data['VirusGenus'].value_counts()[spillover_data['VirusGenus']].values < 5, 'VirusGenus'] = \"Other\"\n",
        "\n",
        "spillover_data.loc[spillover_data['VirusFamily'].value_counts()[spillover_data['VirusFamily']].values < 5, 'VirusFamily'] = \"Other\""
      ],
      "metadata": {
        "id": "kAtbvGnX9Loc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pull out the descriptive and target features\n",
        "X = spillover_data.iloc[:, :-1]\n",
        "y = spillover_data.iloc[:, -1]\n",
        "\n",
        "# binarize the target feature\n",
        "lb = LabelBinarizer()\n",
        "y = lb.fit_transform(y) ## 1 is for Yes, 0 is for No\n",
        "\n",
        "## one-hot encode the categorical features \n",
        "X= pd.get_dummies(X, columns=[\"HostOrder\", \"HostFamily\", \"HostGenus\", \"VirusGenus\", \"VirusFamily\", \"Genome_General\", \"Segmented\", \"Envelope\", \"SeverityDiseaseHumans\", \"ChronicityHumans\"])\n",
        "\n",
        "## split data into train and test sets\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size= 0.3, train_size= 0.7, random_state=10)\n",
        "\n",
        "# balance the training dataset by oversampling the minority class\n",
        "oversample = RandomOverSampler(sampling_strategy='minority')\n",
        "X_train, y_train = oversample.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "Ab65EJYL9ORi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "Ae7wcHj5cApq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## use a contingency table to look at the associations between descriptive features and the target feature\n",
        "host_genus_trans = pd.DataFrame(pd.crosstab(spillover_data['HostGenus'], spillover_data['HumanToHumanTransVirus'], margins = False))\n",
        "host_genus_trans = host_genus_trans.sort_values(by=['Yes'], ascending=False)\n",
        "print(host_genus_trans.head(n=5))\n",
        "\n",
        "host_order_trans = pd.DataFrame(pd.crosstab(spillover_data['HostOrder'], spillover_data['HumanToHumanTransVirus'], margins = False))\n",
        "host_order_trans = host_order_trans.sort_values(by=['Yes'], ascending=False)\n",
        "print(host_order_trans.head(n=5))\n",
        "\n",
        "host_family_trans = pd.DataFrame(pd.crosstab(spillover_data['HostFamily'], spillover_data['HumanToHumanTransVirus'], margins = False))\n",
        "host_family_trans = host_family_trans.sort_values(by=['Yes'], ascending=False)\n",
        "print(host_family_trans.head(n=5))\n",
        "\n",
        "genome_trans = pd.DataFrame(pd.crosstab(spillover_data['Genome_General'], spillover_data['HumanToHumanTransVirus'], margins = False))\n",
        "print(genome_trans) \n",
        "\n",
        "segmented_trans = pd.DataFrame(pd.crosstab(spillover_data['Segmented'], spillover_data['HumanToHumanTransVirus'], margins = False))\n",
        "print(segmented_trans) ## segmentation: when it works, it works (check to see if those 10 are like flu viruses)\n",
        "\n",
        "envelope_trans = pd.DataFrame(pd.crosstab(spillover_data['Envelope'], spillover_data['HumanToHumanTransVirus'], margins = False))\n",
        "print(envelope_trans) ## most of the H2H viruses are enveloped, but a higher proportion of the non-enveloped viruses are H2H\n",
        "\n",
        "virus_genus_trans = pd.DataFrame(pd.crosstab(spillover_data['VirusGenus'], spillover_data['HumanToHumanTransVirus'], margins = False))\n",
        "virus_genus_trans = virus_genus_trans.sort_values(by=['Yes'], ascending=False)\n",
        "print(virus_genus_trans.head(n=5))\n",
        "\n",
        "virus_family_trans = pd.DataFrame(pd.crosstab(spillover_data['VirusFamily'], spillover_data['HumanToHumanTransVirus'], margins = False))\n",
        "virus_family_trans = virus_family_trans.sort_values(by=['Yes'], ascending=False)\n",
        "print(virus_family_trans) ## some of the findings of this are consistent with the graph here: https://journals.plos.org/plospathogens/article?id=10.1371/journal.ppat.1006215\n",
        "\n",
        "severity_trans = pd.DataFrame(pd.crosstab(spillover_data['SeverityDiseaseHumans'], spillover_data['HumanToHumanTransVirus'], margins = False))\n",
        "print(severity_trans)\n",
        "\n",
        "chronicity_trans = pd.DataFrame(pd.crosstab(spillover_data['ChronicityHumans'], spillover_data['HumanToHumanTransVirus'], margins = False))\n",
        "print(chronicity_trans)\n",
        "\n",
        "transmission_trans = pd.DataFrame(pd.crosstab(spillover_data['Total_transmission'], spillover_data['HumanToHumanTransVirus'], margins = False))\n",
        "print(transmission_trans)"
      ],
      "metadata": {
        "id": "4Hss86SseIcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## visualize the contingency tables with stacked bar plots\n",
        "transmission_trans.plot(kind='bar', stacked=True)\n",
        "plt.title(\"Distribution of Transmission Modes\")\n",
        "plt.xlabel(\"Number of Transmission Modes\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=360)\n",
        "plt.legend(title=\"H2H Virus\")"
      ],
      "metadata": {
        "id": "LlnZsAK4c0gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chronicity_trans.plot(kind='bar', stacked=True)\n",
        "plt.title(\"Distribution of Chronicity\")\n",
        "plt.xlabel(\"Chronicity\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=360)\n",
        "plt.legend(title=\"H2H Virus\")"
      ],
      "metadata": {
        "id": "NwQXrpKiXboJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "severity_trans.plot(kind='bar', stacked=True)\n",
        "plt.title(\"Distribution of Severity\")\n",
        "plt.xlabel(\"Severity\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=360)\n",
        "plt.legend(title=\"H2H Virus\")"
      ],
      "metadata": {
        "id": "gUVAJCAkYMBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "envelope_trans.plot(kind='bar', stacked=True)\n",
        "plt.title(\"Distribution of Viral Envelope\")\n",
        "plt.xlabel(\"Presence of Viral Envelope\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=360)\n",
        "plt.legend(title=\"H2H Virus\")"
      ],
      "metadata": {
        "id": "SD-557cLYPh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segmented_trans.plot(kind='bar', stacked=True)\n",
        "plt.title(\"Distribution of RNA Segmentation\")\n",
        "plt.xlabel(\"Presence of Segmentation\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=360)\n",
        "plt.legend(title=\"H2H Virus\")"
      ],
      "metadata": {
        "id": "O0VXN0lcYUIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genome_trans.plot(kind='bar', stacked=True)\n",
        "plt.title(\"Distribution of Genome Type\")\n",
        "plt.xlabel(\"Genome Type\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=360)\n",
        "plt.legend(title=\"H2H Virus\")"
      ],
      "metadata": {
        "id": "GH5m1HssYX5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## look at which descriptive features are most predictive of the target variable\n",
        "pps.predictors(spillover_data, 'HumanToHumanTransVirus', output='df', sorted= True)[['x', 'ppscore']]"
      ],
      "metadata": {
        "id": "Cs6GnloZcnt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## perform feature selection based on chi-squared scores\n",
        "select = SelectKBest(score_func= chi2, k=10)\n",
        "best = select.fit_transform(X, y)\n",
        "\n",
        "names = select.get_support()\n",
        "all_features = np.array(X.columns)\n",
        "best = all_features[names]\n",
        "\n",
        "print(best)"
      ],
      "metadata": {
        "id": "vlNIXTIMdigT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Selection"
      ],
      "metadata": {
        "id": "yjCFIpNybnFp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Information-Based Classification Models"
      ],
      "metadata": {
        "id": "16qujeYZbbMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## use GridSearchCV to tune model hyperparameters (reference: https://towardsdatascience.com/gridsearchcv-for-beginners-db48a90114ee; https://towardsdatascience.com/imbalanced-class-sizes-and-classification-models-a-cautionary-tale-part-2-cf371500d1b3)\n",
        "dt_pipeline = Pipeline([('sampling', RandomOverSampler()), ('class', DecisionTreeClassifier(random_state=10))])\n",
        "\n",
        "params = {'class__criterion': ['gini', 'entropy'],\n",
        "        'class__max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
        "\n",
        "gs_decision_tree = GridSearchCV(dt_pipeline, params, scoring='f1', cv= 10) \n",
        "gs_decision_tree.fit(X_train, y_train)\n",
        "print(\"Best Parameters:\", gs_decision_tree.best_params_)\n",
        "\n",
        "## train a decision tree model on the data\n",
        "decision_tree = DecisionTreeClassifier(random_state= 10, criterion='entropy', max_depth=9) \n",
        "decision_tree = decision_tree.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = decision_tree.predict(X_train)\n",
        "y_test_pred= decision_tree.predict(X_test)\n",
        "\n",
        "## print the confusion matrices for the training and testing datasets\n",
        "print(\"Decision Tree Training Dataset Confusion Matrix\\n\", confusion_matrix(y_train, y_train_pred))\n",
        "print(\"Decision Tree Testing Dataset Confusion Matrix\\n\", confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "## report the accuracy score of the model on the training and testing datasets\n",
        "print(\"Training Accuracy:\", fbeta_score(y_train, y_train_pred, beta=1))\n",
        "print(\"Testing Accuracy:\", fbeta_score(y_test, y_test_pred, beta=1)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg1Kmgdzbp2f",
        "outputId": "d7647fc7-b4ca-40e3-e3ca-964652f0f8ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Training Dataset Confusion Matrix\n",
            " [[248   8]\n",
            " [  0 256]]\n",
            "Decision Tree Testing Dataset Confusion Matrix\n",
            " [[101   4]\n",
            " [  1  21]]\n",
            "Training Accuracy: 0.9846153846153847\n",
            "Testing Accuracy: 0.8936170212765958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## use GridSearchCV to tune model hyperparameters \n",
        "rf_pipeline = Pipeline([('sampling', RandomOverSampler()), ('class', RandomForestClassifier())])\n",
        "\n",
        "params = {'class__criterion': ['gini', 'entropy'],\n",
        "        'class__n_estimators': [10, 15, 25, 50, 100, 150, 200],\n",
        "        'class__max_depth': [5, 10, 15]}\n",
        "\n",
        "rf_gs = GridSearchCV(rf_pipeline, params, scoring='f1', cv= 10)\n",
        "rf_gs.fit(X_train, y_train)\n",
        "print(\"Best Parameters:\", rf_gs.best_params_)\n",
        "\n",
        "## train a Random Forest classifier on the data\n",
        "random_forest = RandomForestClassifier(random_state= 10, n_estimators= 100, max_depth= 15, criterion= 'gini')\n",
        "random_forest = random_forest.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = random_forest.predict(X_train)\n",
        "y_test_pred = random_forest.predict(X_test)\n",
        "\n",
        "print(\"Random Forest Training Dataset Confusion Matrix\\n\", confusion_matrix(y_train, y_train_pred))\n",
        "print(\"Random Forest Testing Dataset Confusion Matrix\\n\", confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "## report the accuracy score of the model on the training and testing datasets\n",
        "print(\"Training Accuracy:\", fbeta_score(y_train, y_train_pred, beta=1))\n",
        "print(\"Testing Accuracy:\", fbeta_score(y_test, y_test_pred, beta=1)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4TO-qO2YFwI",
        "outputId": "68dfa8b5-4d19-4170-b2fa-2b71f1ed59a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Training Dataset Confusion Matrix\n",
            " [[246   7]\n",
            " [  0 253]]\n",
            "Random Forest Testing Dataset Confusion Matrix\n",
            " [[107   1]\n",
            " [  1  18]]\n",
            "Training Accuracy: 0.98635477582846\n",
            "Testing Accuracy: 0.9473684210526315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Similarity-Based Classification Models"
      ],
      "metadata": {
        "id": "WtMdYEXYIodi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## use GridSearchCV to tune model hyperparameters \n",
        "knn_pipeline = Pipeline([('sampling', RandomOverSampler()), ('class', KNeighborsClassifier())])\n",
        "\n",
        "params = {'class__n_neighbors': [1, 3, 5, 7, 9],\n",
        "           'class__weights': ['uniform', 'distance']}\n",
        "\n",
        "gs_knn = GridSearchCV(knn_pipeline, params, scoring='f1', cv= 5)\n",
        "gs_knn.fit(X_train, y_train)\n",
        "print(\"Best Parameters:\", gs_knn.best_params_)\n",
        "\n",
        "## train a Nearest Neighbor binary classification model on the data\n",
        "knn = KNeighborsClassifier(n_neighbors = 1, weights= 'uniform')\n",
        "knn = knn.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = knn.predict(X_train)\n",
        "y_test_pred = knn.predict(X_test)\n",
        "\n",
        "## display the confusion matrix \n",
        "print(\"\\nK Nearest Neighbor Training Dataset Confusion Matrix\\n\", confusion_matrix(y_train, y_train_pred))\n",
        "print(\"K Nearest Neighbor Testing Dataset Confusion Matrix\\n\", confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "## report the accuracy score of the model on the training and testing datasets\n",
        "print(\"\\nTraining Accuracy:\", fbeta_score(y_train, y_train_pred, beta=1))\n",
        "print(\"Testing Accuracy:\", fbeta_score(y_test, y_test_pred, beta=1)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM3tMgLxIrEB",
        "outputId": "37554477-d5c6-41bf-8e76-c87a36a82c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "K Nearest Neighbor Training Dataset Confusion Matrix\n",
            " [[256   0]\n",
            " [ 18 238]]\n",
            "K Nearest Neighbor Testing Dataset Confusion Matrix\n",
            " [[103   2]\n",
            " [  2  20]]\n",
            "\n",
            "Training Accuracy: 0.9635627530364372\n",
            "Testing Accuracy: 0.9090909090909091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Probability-Based Classification Models"
      ],
      "metadata": {
        "id": "hqoN_24JLCZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## create a Naive Bayes classifier\n",
        "naive_bayes = BernoulliNB()\n",
        "naive_bayes = naive_bayes.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = naive_bayes.predict(X_train)\n",
        "y_test_pred = naive_bayes.predict(X_test)\n",
        "\n",
        "## display the confusion matrix \n",
        "print(\"Naive Bayes Training Dataset Confusion Matrix\\n\", confusion_matrix(y_train, y_train_pred))\n",
        "print(\"Naive Bayes Testing Dataset Confusion Matrix\\n\", confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "## report the F2 score for the training and testing datasets\n",
        "print(\"Training Accuracy:\", fbeta_score(y_train, y_train_pred, beta=1))\n",
        "print(\"Testing Accuracy:\", fbeta_score(y_test, y_test_pred, beta=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl7keFq9LEUG",
        "outputId": "817d6dc4-1b59-4255-cb42-bad70e48554a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Training Dataset Confusion Matrix\n",
            " [[224  32]\n",
            " [  8 248]]\n",
            "Naive Bayes Testing Dataset Confusion Matrix\n",
            " [[91 14]\n",
            " [ 3 19]]\n",
            "Training Accuracy: 0.9253731343283582\n",
            "Testing Accuracy: 0.6909090909090909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Error-Based Classification Models"
      ],
      "metadata": {
        "id": "WwQezen-kdDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## create a Logistic Regression classifier\n",
        "logreg = LogisticRegression(random_state= 10, penalty= 'l1', solver='liblinear') ## l1 is lasso regression (https://www.statisticshowto.com/lasso-regression/) and liblinear (https://holypython.com/log-reg/logistic-regression-optimization-parameters/)\n",
        "logreg = logreg.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = logreg.predict(X_train)\n",
        "y_test_pred = logreg.predict(X_test)\n",
        "\n",
        "## display the confusion matrix \n",
        "print(\"Logistic Regression Training Dataset Confusion Matrix\\n\", confusion_matrix(y_train, y_train_pred))\n",
        "print(\"Logistic Regression Testing Dataset Confusion Matrix\\n\", confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "## report the F2 score for the training and testing datasets\n",
        "print(\"Training Dataset F2 Score:\", fbeta_score(y_train, y_train_pred, beta=1.0))\n",
        "print(\"Testing Dataset F2 Score:\", fbeta_score(y_test, y_test_pred, beta=1.0)) "
      ],
      "metadata": {
        "id": "ul-UGZ6hkgO_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56b4472a-d9ec-4873-f701-11595e65cbef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Training Dataset Confusion Matrix\n",
            " [[244  12]\n",
            " [  0 256]]\n",
            "Logistic Regression Testing Dataset Confusion Matrix\n",
            " [[95 10]\n",
            " [ 2 20]]\n",
            "Training Dataset F2 Score: 0.9770992366412213\n",
            "Testing Dataset F2 Score: 0.7692307692307692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## use GridSearchCV to tune model hyperparameters \n",
        "svm_pipeline = Pipeline([('sampling', RandomOverSampler()), ('class', SVC())])\n",
        "\n",
        "params = {'class__kernel': ['linear'], ## linear kernel is used here because feature coefficients are only available for the linear kernel\n",
        "          'class__C': [0.5, 1.0, 10, 100],\n",
        "          'class__gamma': ['scale', 'auto']}\n",
        "\n",
        "gs_svm = GridSearchCV(svm_pipeline, params, scoring='f1', cv= 10)\n",
        "gs_svm.fit(X_train, y_train)\n",
        "print(gs_svm.best_params_)\n",
        "\n",
        "## create a Support Vector Machine classifier\n",
        "svm = SVC(kernel='linear', C=10) ## gamma= 'scale' is the default\n",
        "svm = svm.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = svm.predict(X_train)\n",
        "y_test_pred = svm.predict(X_test)\n",
        "\n",
        "## display the confusion matrix \n",
        "print(\"SVM Training Dataset Confusion Matrix\\n\", confusion_matrix(y_train, y_train_pred))\n",
        "print(\"SVM Testing Dataset Confusion Matrix\\n\", confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "## report the F2 score for the training and testing datasets\n",
        "print(\"Training Dataset F2 Score:\", fbeta_score(y_train, y_train_pred, beta=1.0))\n",
        "print(\"Testing Dataset F2 Score:\", fbeta_score(y_test, y_test_pred, beta=1.0))"
      ],
      "metadata": {
        "id": "X2Uz05r3kiS1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f9d5220-4fd7-42cb-8088-7ab7333bd5ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Training Dataset Confusion Matrix\n",
            " [[245   8]\n",
            " [  0 253]]\n",
            "SVM Testing Dataset Confusion Matrix\n",
            " [[106   2]\n",
            " [  4  15]]\n",
            "Training Dataset F2 Score: 0.9844357976653696\n",
            "Testing Dataset F2 Score: 0.8333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Importance"
      ],
      "metadata": {
        "id": "GlMtn3emzkTv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The random forest classifier was the best performing model, with a training accuracy of 0.9865 and a testing accuracy of 0.947."
      ],
      "metadata": {
        "id": "SvFHhN-3-2GD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree_estimator = RandomForestClassifier(random_state= 10, n_estimators= 100, criterion= 'gini')\n",
        "tree_estimator.fit(X_train, y_train)\n",
        "\n",
        "feats = {} # reference: https://machinelearningmastery.com/calculate-feature-importance-with-python/; https://stackoverflow.com/questions/41900387/mapping-column-names-to-random-forest-feature-importances\n",
        "for feature, importance in zip(X.columns, tree_estimator.feature_importances_):\n",
        "    feats[feature] = importance\n",
        "\n",
        "importance_df = pd.DataFrame.from_dict(feats, orient='index', columns=['Feature Importance'])\n",
        "importance_df = importance_df.sort_values(by= ['Feature Importance'], ascending= False)\n",
        "\n",
        "print(importance_df.head(n=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTKwL2KvLCJT",
        "outputId": "9a0c1d0e-2bcc-4226-f9b7-01b4612c8d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              Feature Importance\n",
            "SeverityDiseaseHumans_None              0.152038\n",
            "ChronicityHumans_Acute                  0.114404\n",
            "SeverityDiseaseHumans_Deadly            0.081531\n",
            "VirusGenus_Lyssavirus                   0.073241\n",
            "VirusFamily_Rhabdoviridae               0.068231\n",
            "ChronicityHumans_None                   0.063312\n",
            "Total_transmission                      0.028674\n",
            "HostOrder_Chiroptera                    0.023747\n",
            "VirusGenus_Orthohepevirus               0.014934\n",
            "VirusFamily_Paramyxoviridae             0.014515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## fit a logit-link model using severity, chronicity, transmission, genome type, segmentation, and envelope\n",
        "formula = 'HumanToHumanTransVirus ~ SeverityDiseaseHumans+ChronicityHumans+Total_transmission+Genome_General+Segmented+Envelope'\n",
        "\n",
        "model = smf.glm(formula = formula, data=spillover_data, family= sm.families.Binomial())\n",
        "result = model.fit()\n",
        "print(result.summary())"
      ],
      "metadata": {
        "id": "rSsXqZeBINhb",
        "outputId": "c86a038a-2291-4df1-92dd-b00033e30a42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       Generalized Linear Model Regression Results                                       \n",
            "=========================================================================================================================\n",
            "Dep. Variable:     ['HumanToHumanTransVirus[No]', 'HumanToHumanTransVirus[Yes]']   No. Observations:                  423\n",
            "Model:                                                                       GLM   Df Residuals:                      413\n",
            "Model Family:                                                           Binomial   Df Model:                            9\n",
            "Link Function:                                                             logit   Scale:                          1.0000\n",
            "Method:                                                                     IRLS   Log-Likelihood:                    nan\n",
            "Date:                                                           Sat, 11 Dec 2021   Deviance:                          nan\n",
            "Time:                                                                   00:44:28   Pearson chi2:                     165.\n",
            "No. Iterations:                                                              100                                         \n",
            "Covariance Type:                                                       nonrobust                                         \n",
            "==========================================================================================================\n",
            "                                             coef    std err          z      P>|z|      [0.025      0.975]\n",
            "----------------------------------------------------------------------------------------------------------\n",
            "Intercept                                -89.6172   8.45e+06  -1.06e-05      1.000   -1.66e+07    1.66e+07\n",
            "SeverityDiseaseHumans[T.MildIllness]      41.4750   1.31e+07   3.17e-06      1.000   -2.57e+07    2.57e+07\n",
            "SeverityDiseaseHumans[T.None]            -12.2265   6.84e+07  -1.79e-07      1.000   -1.34e+08    1.34e+08\n",
            "SeverityDiseaseHumans[T.SevereIllness]     1.2183      1.128      1.080      0.280      -0.992       3.429\n",
            "ChronicityHumans[T.Chronic]               49.0311   6.76e+07   7.25e-07      1.000   -1.33e+08    1.33e+08\n",
            "ChronicityHumans[T.None]                 138.7643    6.9e+07   2.01e-06      1.000   -1.35e+08    1.35e+08\n",
            "Genome_General[T.RNA]                      2.3584      0.836      2.820      0.005       0.719       3.997\n",
            "Segmented[T.Yes]                          -0.3485      0.490     -0.712      0.477      -1.308       0.611\n",
            "Envelope[T.Yes]                           89.9339   8.45e+06   1.06e-05      1.000   -1.66e+07    1.66e+07\n",
            "Total_transmission                        -0.9053      0.314     -2.886      0.004      -1.520      -0.290\n",
            "==========================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:890: RuntimeWarning: invalid value encountered in true_divide\n",
            "  n_endog_mu = self._clean((1. - endog) / (1. - mu))\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:942: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu)) +\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:943: RuntimeWarning: divide by zero encountered in log\n",
            "  n * np.log(1 - mu)) * var_weights\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:943: RuntimeWarning: invalid value encountered in add\n",
            "  n * np.log(1 - mu)) * var_weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## fit a logit-link model using viral genomic characteristics (genomic material, envelope, segmentation)\n",
        "formula = 'HumanToHumanTransVirus ~ Genome_General+Segmented+Total_transmission'\n",
        "\n",
        "model = smf.glm(formula = formula, data=spillover_data, family= sm.families.Binomial())\n",
        "result = model.fit()\n",
        "print(result.summary())"
      ],
      "metadata": {
        "id": "OmvQomoBIRfm",
        "outputId": "4338f12e-425c-460a-fc4c-9eed305dd89f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       Generalized Linear Model Regression Results                                       \n",
            "=========================================================================================================================\n",
            "Dep. Variable:     ['HumanToHumanTransVirus[No]', 'HumanToHumanTransVirus[Yes]']   No. Observations:                  423\n",
            "Model:                                                                       GLM   Df Residuals:                      419\n",
            "Model Family:                                                           Binomial   Df Model:                            3\n",
            "Link Function:                                                             logit   Scale:                          1.0000\n",
            "Method:                                                                     IRLS   Log-Likelihood:                -168.09\n",
            "Date:                                                           Sat, 11 Dec 2021   Deviance:                       336.19\n",
            "Time:                                                                   00:44:31   Pearson chi2:                     412.\n",
            "No. Iterations:                                                                5                                         \n",
            "Covariance Type:                                                       nonrobust                                         \n",
            "=========================================================================================\n",
            "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
            "-----------------------------------------------------------------------------------------\n",
            "Intercept                 0.1682      0.465      0.362      0.717      -0.742       1.079\n",
            "Genome_General[T.RNA]     1.1966      0.375      3.192      0.001       0.462       1.931\n",
            "Segmented[T.Yes]         -0.8054      0.402     -2.003      0.045      -1.593      -0.017\n",
            "Total_transmission        0.3843      0.180      2.134      0.033       0.031       0.737\n",
            "=========================================================================================\n"
          ]
        }
      ]
    }
  ]
}